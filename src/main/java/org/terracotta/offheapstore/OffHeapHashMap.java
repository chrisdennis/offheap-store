/* 
 * Copyright 2015 Terracotta, Inc., a Software AG company.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.terracotta.offheapstore;

import java.nio.ByteBuffer;
import java.util.AbstractMap;
import java.util.AbstractSet;
import java.util.ConcurrentModificationException;
import java.util.Iterator;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Set;
import java.util.concurrent.locks.Lock;

import org.terracotta.offheapstore.buffersource.BufferSource;
import org.terracotta.offheapstore.exceptions.OversizeMappingException;
import org.terracotta.offheapstore.storage.BinaryStorageEngine;
import org.terracotta.offheapstore.storage.StorageEngine;
import org.terracotta.offheapstore.util.DebuggingUtils;
import org.terracotta.offheapstore.util.FindbugsSuppressWarnings;
import org.terracotta.offheapstore.util.NoOpLock;
import org.terracotta.offheapstore.util.WeakIdentityHashMap;
import org.terracotta.offheapstore.util.WeakIdentityHashMap.ReaperTask;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.terracotta.offheapstore.data.Data;
import org.terracotta.offheapstore.data.IntData;
import org.terracotta.offheapstore.data.Source;

/**
 * A hash-table implementation whose table is stored in an NIO direct buffer.
 * <p>
 * The map stores keys and values encoded as integers, in an open-addressed
 * linear-reprobing hashtable.  Entries are 16-bytes wide, and consist of:
 * <ul>
 *   <li><code>int</code> status marker</li>
 *   <li><code>int</code> cached key hashcode</li>
 *   <li><code>long</code> {key:value} representation</li>
 * </ul>
 * Key and value representations are generated by the {@link StorageEngine}
 * instance provided at construction time.
 * <p>
 * This {@link Map} implementation is not thread-safe and does not support null
 * keys or values.
 *
 * @param <K> the type of keys maintained by this map
 * @param <V> the type of mapped values
 *
 * @author Chris Dennis
 */
public class OffHeapHashMap<K, V> extends AbstractMap<K, V> implements MapInternals, StorageEngine.Owner {

  /*
   * Future design ideas:
   *
   * We might want to look in to reading the whole (or large chunks) of the
   * probe sequence for a key in one shot rather than doing it one by one.
   */

  private static final Logger LOGGER = LoggerFactory.getLogger(OffHeapHashMap.class);

  private static final int INITIAL_TABLE_SIZE = 128;
  private static final float TABLE_RESIZE_THRESHOLD = 0.5f;
  private static final float TABLE_SHRINK_THRESHOLD = 0.2f;
  private static final int INITIAL_REPROBE_LENGTH = 16;
  private static final int REPROBE_WARNING_THRESHOLD = 1024;
  private static final int ALLOCATE_ON_CLEAR_THRESHOLD_RATIO = 2;

  private static final IntData DESTROYED_TABLE = Data.emptyIntData();
  
  /**
   * Size of a table entry in primitive {@code int} units
   */
  protected static final int ENTRY_SIZE = 4;
  private static final int ENTRY_BIT_SHIFT = Integer.numberOfTrailingZeros(ENTRY_SIZE);

  protected static final int STATUS = 0;
  private static final int KEY_HASHCODE = 1;
  private static final int ENCODING = 2;

  protected static final int STATUS_USED = 1;
  private static final int STATUS_REMOVED = 2;
  public static final int RESERVED_STATUS_BITS = STATUS_USED | STATUS_REMOVED;

  protected final StorageEngine<? super K, ? super V> storageEngine;

  protected final Source<IntData> tableSource;

  private final WeakIdentityHashMap<IntData, PendingPage> pendingTableFrees = new WeakIdentityHashMap<IntData, PendingPage>(new ReaperTask<PendingPage>() {
    @Override
    public void reap(PendingPage pending) {
      freeTable(pending.table);
    }
  });

  private final int initialTableSize;

  private final boolean tableAllocationsSteal;

  private final ThreadLocal<Boolean> tableResizing = new ThreadLocal<Boolean>() {

    @Override
    protected Boolean initialValue() {
      return Boolean.FALSE;
    };
  };

  protected volatile int size;

  protected volatile int modCount;

  /*
   * The reprobe limit as it currently stands only ever increases.  If we change
   * this behavior we will need to make changes to the iterators as they assume
   * this to be true.
   */
  protected int reprobeLimit = INITIAL_REPROBE_LENGTH;

  private float currentTableShrinkThreshold = TABLE_SHRINK_THRESHOLD;

  private volatile boolean hasUsedIterators;

  /**
   * The current hash-table.
   * <p>
   * A list of: {@code int[] {status, hashCode, encoding-high, encoding-low}}
   */
  protected volatile IntData hashtable;

  private Set<Entry<K, V>> entrySet;
  private Set<K> keySet;
  private Set<Long> encodingSet;

  /*
   * Statistics support
   */
  protected volatile int removedSlots;

  /**
   * Construct an instance using a custom {@link BufferSource} for the
   * hashtable.
   *
   * @param source source for the hashtable allocations
   * @param storageEngine engine used to encode the keys and values
   */
  public OffHeapHashMap(Source<IntData> source, StorageEngine<? super K, ? super V> storageEngine) {
    this(source, storageEngine, INITIAL_TABLE_SIZE);
  }

  public OffHeapHashMap(Source<IntData> source, boolean tableAllocationsSteal, StorageEngine<? super K, ? super V> storageEngine) {
    this(source, tableAllocationsSteal, storageEngine, INITIAL_TABLE_SIZE);
  }

  public OffHeapHashMap(Source<IntData> source, StorageEngine<? super K, ? super V> storageEngine, boolean bootstrap) {
    this(source, false, storageEngine, INITIAL_TABLE_SIZE, bootstrap);
  }

  /**
   * Construct an instance using a custom {@link BufferSource} for the
   * hashtable and a custom initial table size.
   *
   * @param source source for the hashtable allocations
   * @param storageEngine engine used to encode the keys and values
   * @param tableSize the initial table size
   */
  public OffHeapHashMap(Source<IntData> source, StorageEngine<? super K, ? super V> storageEngine, int tableSize) {
    this(source, false, storageEngine, tableSize, true);
  }

  public OffHeapHashMap(Source<IntData> source, boolean tableAllocationsSteal, StorageEngine<? super K, ? super V> storageEngine, int tableSize) {
    this(source, tableAllocationsSteal, storageEngine, tableSize, true);
  }

  @FindbugsSuppressWarnings("ICAST_INTEGER_MULTIPLY_CAST_TO_LONG")
  protected OffHeapHashMap(Source<IntData> source, boolean tableAllocationsSteal, StorageEngine<? super K, ? super V> storageEngine, int tableSize, boolean bootstrap) {
    if (storageEngine == null) {
      throw new NullPointerException("StorageEngine implementation must be non-null");
    }

    this.storageEngine = storageEngine;
    this.tableSource = source;
    this.tableAllocationsSteal = tableAllocationsSteal;

    // Find a power of 2 >= initialCapacity
    int capacity = 1;
    while (capacity < tableSize) {
        capacity <<= 1;
    }
    this.initialTableSize = capacity;

    if (bootstrap) {
      this.hashtable = allocateTable(initialTableSize);
      if (hashtable == null) {
        StringBuilder sb = new StringBuilder("Initial table allocation failed.\n");
        sb.append("Initial Table Size (slots) : ").append(initialTableSize).append('\n');
        sb.append("Allocation Will Require    : ").append(DebuggingUtils.toBase2SuffixedString(initialTableSize * ENTRY_SIZE * (Integer.SIZE / Byte.SIZE))).append("B\n");
        sb.append("Table Page Source        : ").append(tableSource);
        throw new IllegalArgumentException(sb.toString());
      }
    }
    this.storageEngine.bind(this);
  }

  @Override
  public int size() {
    return size;
  }

  @Override
  public boolean containsKey(Object key) {
    int hash = key.hashCode();

    if (size == 0) {
      return false;
    }
    
    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return false;
      } else if (isPresent(entry) && keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        hit(entry);
        return true;
      } else {
        position += ENTRY_SIZE;
      }
    }
    return false;
  }

  @SuppressWarnings("unchecked")
  @Override
  public V get(Object key) {
    int hash = key.hashCode();

    if (size == 0) {
      return null;
    }
    
    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return null;
      } else if (isPresent(entry) && keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        hit(entry);
        return (V) storageEngine.readValue(readLong(entry, ENCODING));
      } else {
        position += ENTRY_SIZE;
      }
    }
    return null;
  }

  @Override
  public Long getEncodingForHashAndBinary(int hash, ByteBuffer binaryKey) {
    if (size == 0) {
      return null;
    }
    
    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return null;
      } else if (isPresent(entry) && binaryKeyEquals(binaryKey, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        return readLong(entry, ENCODING);
      } else {
        position += ENTRY_SIZE;
      }
    }
    return null;
  }
  
  @Override
  @FindbugsSuppressWarnings("VO_VOLATILE_INCREMENT")
  public long installMappingForHashAndEncoding(int pojoHash, ByteBuffer offheapBinaryKey, ByteBuffer offheapBinaryValue, int metadata) {
    freePendingTables();

    int[] newEntry = installEntry(offheapBinaryKey, pojoHash, offheapBinaryValue, metadata);

    long start = indexFor(spread(pojoHash));
    long position = start;

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isAvailable(entry)) {
        if (isRemoved(entry)) {
          removedSlots--;
        }
        entry.put(0, newEntry);
        slotAdded(entry);
        hit(entry);
        return readLong(newEntry, ENCODING);
      } else {
        position += ENTRY_SIZE;
      }
    }

    storageEngine.freeMapping(readLong(newEntry, ENCODING), newEntry[KEY_HASHCODE], false); //XXX: further contemplate the boolean value here

    // hit reprobe limit - must rehash
    expand(start, limit);
    
    return installMappingForHashAndEncoding(pojoHash, offheapBinaryKey, offheapBinaryValue, metadata);
  }

  public boolean updateMetadata(K key, int writeMask, int metadata) {
    freePendingTables();

    int hash = key.hashCode();

    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      long encoding = readLong(entry, ENCODING);
      if (isTerminating(entry)) {
        return false;
      } else if (isPresent(entry) && keyEquals(key, hash, encoding, entry.get(KEY_HASHCODE))) {
        entry.put(STATUS, (entry.get(STATUS) & (RESERVED_STATUS_BITS | ~writeMask)) | (metadata & (writeMask & ~RESERVED_STATUS_BITS)));
        return true;
      } else {
        position += ENTRY_SIZE;
      }
    }

    return false;
  }

  @Override
  public V put(K key, V value) {
    return put(key, value, 0);
  }

  @SuppressWarnings("unchecked")
  @FindbugsSuppressWarnings("VO_VOLATILE_INCREMENT")
  public V put(K key, V value, int metadata) {
    freePendingTables();

    int hash = key.hashCode();

    int[] newEntry = writeEntry(key, hash, value, metadata);

    long start = indexFor(spread(hash));
    long position = start;
    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isAvailable(entry)) {
        storageEngine.attachedMapping(readLong(newEntry, ENCODING), hash, metadata);
        storageEngine.invalidateCache();
        for (IntData laterEntry = entry; i < limit; i++) {
          if (isTerminating(laterEntry)) {
            break;
          } else if (isPresent(laterEntry) && keyEquals(key, hash, readLong(laterEntry, ENCODING), laterEntry.get(KEY_HASHCODE))) {
            V old = (V) storageEngine.readValue(readLong(laterEntry, ENCODING));
            storageEngine.freeMapping(readLong(laterEntry, ENCODING), laterEntry.get(KEY_HASHCODE), false);
            long oldEncoding = readLong(laterEntry, ENCODING);
            laterEntry.put(0, newEntry);
            slotUpdated(laterEntry, oldEncoding);
            hit(laterEntry);
            return old;
          } else {
            position += ENTRY_SIZE;
          }

          if (position == hashtable.size()) {
            position = 0;
          }

          laterEntry = hashtable.slice(position, ENTRY_SIZE);
        }
        if (isRemoved(entry)) {
          removedSlots--;
        }
        entry.put(0, newEntry);
        slotAdded(entry);
        hit(entry);
        return null;
      } else if (keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        storageEngine.attachedMapping(readLong(newEntry, ENCODING), hash, metadata);
        storageEngine.invalidateCache();
        V old = (V) storageEngine.readValue(readLong(entry, ENCODING));
        storageEngine.freeMapping(readLong(entry, ENCODING), entry.get(KEY_HASHCODE), false);
        long oldEncoding = readLong(entry, ENCODING);
        entry.put(0, newEntry);
        slotUpdated(entry, oldEncoding);
        hit(entry);
        return old;
      } else {
        position += ENTRY_SIZE;
      }
    }

    storageEngine.freeMapping(readLong(newEntry, ENCODING), newEntry[KEY_HASHCODE], false); //XXX: further contemplate the boolean value here

    // hit reprobe limit - must rehash
    expand(start, limit);

    return put(key, value, metadata);
  }

  public int getMetadata(Object key) {
    int hash = key.hashCode();

    if (size == 0) {
      return 0;
    }

    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return 0;
      } else if (isPresent(entry) && keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        return entry.get(STATUS) & ~RESERVED_STATUS_BITS;
      } else {
        position += ENTRY_SIZE;
      }
    }
    return 0;
  }



  /**
   * Associates the specified value with the specified key in this map.  If the
   * map does not contain a mapping for the key, the new mapping is only
   * installed if there is room.  If the map previously contained a mapping for
   * the key, the old value is replaced by the specified value even if this
   * results in a failure or eviction.
   *
   * @param key key with which the specified value is to be associated
   * @param value value to be associated with the specified key
   * @return the previous value associated with <tt>key</tt>, or
   *         <tt>null</tt> if there was no mapping for <tt>key</tt>
   *         (irrespective of whether the value was successfully installed).
   */
  public V fill(K key, V value) {
    return fill(key, value, 0);
  }

  @FindbugsSuppressWarnings("VO_VOLATILE_INCREMENT")
  public V fill(K key, V value, int metadata) {
    freePendingTables();

    int hash = key.hashCode();

    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isAvailable(entry)) {
        for (IntData laterEntry = entry; i < limit; i++) {
          if (isTerminating(laterEntry)) {
            break;
          } else if (isPresent(laterEntry) && keyEquals(key, hash, readLong(laterEntry, ENCODING), laterEntry.get(KEY_HASHCODE))) {
            return put(key, value, metadata);
          } else {
            position += ENTRY_SIZE;
          }

          if (position == hashtable.size()) {
            position = 0;
          }

          laterEntry = hashtable.slice(position, ENTRY_SIZE);
        }

        int[] newEntry = tryWriteEntry(key, hash, value, metadata);
        if (newEntry == null) {
          return null;
        } else {
          return fill(key, value, hash, newEntry, metadata);
        }
      } else if (keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        return put(key, value, metadata);
      } else {
        position += ENTRY_SIZE;
        position += ENTRY_SIZE;
      }
    }

    // hit reprobe limit - must rehash
    if (tryExpandTable()) {
      return fill(key, value, metadata);
    } else {
      return null;
    }
  }

  @SuppressWarnings("unchecked")
  @FindbugsSuppressWarnings("VO_VOLATILE_INCREMENT")
  protected final V fill(K key, V value, int hash, int[] newEntry, int metadata) {
    freePendingTables();

    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isAvailable(entry)) {
        storageEngine.attachedMapping(readLong(newEntry, ENCODING), hash, metadata);
        storageEngine.invalidateCache();
        for (IntData laterEntry = entry; i < limit; i++) {
          if (isTerminating(laterEntry)) {
            break;
          } else if (isPresent(laterEntry) && keyEquals(key, hash, readLong(laterEntry, ENCODING), laterEntry.get(KEY_HASHCODE))) {
            V old = (V) storageEngine.readValue(readLong(laterEntry, ENCODING));
            storageEngine.freeMapping(readLong(laterEntry, ENCODING), laterEntry.get(KEY_HASHCODE), false);
            long oldEncoding = readLong(laterEntry, ENCODING);
            laterEntry.put(0, newEntry);
            slotUpdated(laterEntry, oldEncoding);
            hit(laterEntry);
            return old;
          } else {
            position += ENTRY_SIZE;
          }

          if (position == hashtable.size()) {
            position = 0;
          }

          laterEntry = hashtable.slice(position, ENTRY_SIZE);
        }
        if (isRemoved(entry)) {
          removedSlots--;
        }
        entry.put(0, newEntry);
        slotAdded(entry);
        hit(entry);
        return null;
      } else if (keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        storageEngine.attachedMapping(readLong(newEntry, ENCODING), hash, metadata);
        storageEngine.invalidateCache();
        V old = (V) storageEngine.readValue(readLong(entry, ENCODING));
        storageEngine.freeMapping(readLong(entry, ENCODING), entry.get(KEY_HASHCODE), false);
        long oldEncoding = readLong(entry, ENCODING);
        entry.put(0, newEntry);
        slotUpdated(entry, oldEncoding);
        hit(entry);
        return old;
      } else {
        position += ENTRY_SIZE;
      }
    }

    storageEngine.freeMapping(readLong(newEntry, ENCODING), newEntry[KEY_HASHCODE], true);

    return null;
  }

  private int[] writeEntry(K key, int hash, V value, int metadata) {
    /*
     * TODO If we start supporting remapping (compaction) then we'll need to
     * worry about correcting the key representation here if the value write
     * triggers a remapping operation.
     */
    while (true) {
      int[] entry = tryWriteEntry(key, hash, value, metadata);
      if (entry == null) {
        storageEngineFailure(key);
      } else {
        return entry;
      }
    }
  }

  @FindbugsSuppressWarnings("PZLA_PREFER_ZERO_LENGTH_ARRAYS")
  private int[] tryWriteEntry(K key, int hash, V value, int metadata) {
    if (hashtable == null) {
      throw new NullPointerException();
    } else if (hashtable == DESTROYED_TABLE) {
      throw new IllegalStateException("Offheap map/cache has been destroyed");
    } else if ((metadata & RESERVED_STATUS_BITS) == 0) {
      Long encoding = storageEngine.writeMapping(key, value, hash, metadata);
      if (encoding == null) {
        return null;
      } else {
        return createEntry(hash, encoding, metadata);
      }
    } else {
      throw new IllegalArgumentException("Invalid metadata for key '" + key + "' : " + Integer.toBinaryString(metadata));
    }
  }

  private int[] installEntry(ByteBuffer offheapBinaryKey, int pojoHash, ByteBuffer offheapBinaryValue, int metadata) {
    while (true) {
      int [] entry = tryInstallEntry(offheapBinaryKey, pojoHash, offheapBinaryValue, metadata);
      if (entry == null) {
        storageEngineFailure("<binary-key>");
        continue;
      } else {
        return entry;
      }
    }
  }
  
  @FindbugsSuppressWarnings("PZLA_PREFER_ZERO_LENGTH_ARRAYS")
  private int[] tryInstallEntry(ByteBuffer offheapBinaryKey, int pojoHash, ByteBuffer offheapBinaryValue, int metadata) {
    if (hashtable == null) {
      throw new NullPointerException();
    } else if (hashtable == DESTROYED_TABLE) {
      throw new IllegalStateException("Offheap map/cache has been destroyed");
    } else if ((metadata & RESERVED_STATUS_BITS) == 0) {
      Long encoding = ((BinaryStorageEngine) storageEngine).writeBinaryMapping(offheapBinaryKey, offheapBinaryValue, pojoHash, metadata);
      if (encoding == null) {
        return null;
      } else {
        return createEntry(pojoHash, encoding, metadata);
      }
    } else {
      throw new IllegalArgumentException("Invalid metadata for binary key : " + Integer.toBinaryString(metadata));
    }
  }
  
  private static int[] createEntry(int hash, long encoding, int metadata) {
    return new int[] { STATUS_USED | metadata, hash, (int) (encoding >>> Integer.SIZE), (int) encoding };
  }

  @Override
  public V remove(Object key) {
    freePendingTables();

    int hash = key.hashCode();

    if (size == 0) {
      return null;
    }
    
    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return null;
      } else if (isPresent(entry) && keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        @SuppressWarnings("unchecked")
        V removedValue = (V) storageEngine.readValue(readLong(entry, ENCODING));
        storageEngine.freeMapping(readLong(entry, ENCODING), entry.get(KEY_HASHCODE), true);

        /*
         * TODO We might want to track the number of 'removed' slots in the
         * table, and rehash it if we reach some threshold to avoid lookup costs
         * staying artificially high when the table is relatively empty, but full
         * of 'removed' slots.  This situation should be relatively rare for
         * normal cache usage - but might be more common for more map like usage
         * patterns.
         *
         * The more severe versions of this pattern are now handled by the table
         * shrinking when the occupation drops below the shrink threshold, as
         * that will rehash the table.
         */
        entry.put(STATUS, STATUS_REMOVED);
        slotRemoved(entry);
        shrink();
        return removedValue;
      } else {
        position += ENTRY_SIZE;
      }
    }

    return null;
  }

  public boolean removeNoReturn(Object key) {
    freePendingTables();

    int hash = key.hashCode();

    long position = indexFor(spread(hash));

    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return false;
      } else if (isPresent(entry) && keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))) {
        storageEngine.freeMapping(readLong(entry, ENCODING), entry.get(KEY_HASHCODE), true);

        /*
         * TODO We might want to track the number of 'removed' slots in the
         * table, and rehash it if we reach some threshold to avoid lookup costs
         * staying artificially high when the table is relatively empty, but full
         * of 'removed' slots.  This situation should be relatively rare for
         * normal cache usage - but might be more common for more map like usage
         * patterns.
         *
         * The more severe versions of this pattern are now handled by the table
         * shrinking when the occupation drops below the shrink threshold, as
         * that will rehash the table.
         */
        entry.put(STATUS, STATUS_REMOVED);
        slotRemoved(entry);
        shrink();
        return true;
      } else {
        position += ENTRY_SIZE;
      }
    }
    return false;
  }
  
  @Override
  @FindbugsSuppressWarnings("VO_VOLATILE_INCREMENT")
  public void clear() {
    if (hashtable != DESTROYED_TABLE) {
      freePendingTables();

      modCount++;
      removedSlots = 0;
      size = 0;
      storageEngine.clear();
      allocateOrClearTable(initialTableSize);
    }
  }

  public void destroy() {
    removedSlots = 0;
    size = 0;
    freeTable(hashtable);
    for (Iterator<PendingPage> it = pendingTableFrees.values(); it.hasNext(); freeTable(it.next().table));
    hashtable = DESTROYED_TABLE;
    storageEngine.destroy();
  }

  private void allocateOrClearTable(int size) {
    int[] zeros = new int[1024 >> 2];
    for (long position = 0; position < hashtable.size(); position += zeros.length) {
      long remaining = hashtable.size() - position;
      if (remaining < zeros.length) {
        hashtable.put(position, zeros, 0, (int) remaining);
      } else {
        hashtable.put(position, zeros);
      }
    }
    
    wipePendingTables();
    
    if (hashtable.size() > size * ENTRY_SIZE * ALLOCATE_ON_CLEAR_THRESHOLD_RATIO) {
      IntData newTable = allocateTable(size);
      if (newTable != null) {
        freeTable(hashtable, reprobeLimit());
        hashtable = newTable;
      }
    }
  }

  @Override
  public Set<Entry<K, V>> entrySet() {
    Set<Entry<K, V>> es = entrySet;
    return es == null ? (entrySet = new EntrySet()) : es;
  }

  @Override
  public Set<Long> encodingSet() {
    Set<Long> es = encodingSet;
    return es == null ? (encodingSet = new EncodingSet()) : es;
  }

  @Override
  public Set<K> keySet() {
    Set<K> ks = keySet;
    return ks == null ? (keySet = new KeySet()) : ks;
  }

  protected static boolean isPresent(IntData entry) {
    return (entry.get(STATUS) & STATUS_USED) != 0;
  }

  protected static boolean isAvailable(IntData entry) {
    return (entry.get(STATUS) & STATUS_USED) == 0;
  }

  protected static boolean isTerminating(IntData entry) {
    return isTerminating(entry.get(STATUS));
  }

  private static boolean isTerminating(int entryStatus) {
    return (entryStatus & (STATUS_USED | STATUS_REMOVED)) == 0;
  }

  protected static boolean isRemoved(IntData entry) {
    return isRemoved(entry.get(STATUS));
  }

  private static boolean isRemoved(int entryStatus) {
    return (entryStatus & STATUS_REMOVED) != 0;
  }

  private static long readLong(int[] array, int offset) {
    return (((long) array[offset]) << Integer.SIZE) | (0xffffffffL & array[offset + 1]);
  }

  private static long readLong(IntData entry, int offset) {
    return (((long) entry.get(offset)) << Integer.SIZE) | (0xffffffffL & entry.get(offset + 1));
  }

  private long indexFor(int hash) {
    return indexFor(hash, hashtable);
  }

  private static long indexFor(int hash, IntData table) {
    return (hash << ENTRY_BIT_SHIFT) & Math.max(0, table.size() - 1);
  }

  private boolean keyEquals(Object probeKey, int probeHash, long targetEncoding, int targetHash) {
    return probeHash == targetHash && storageEngine.equalsKey(probeKey, targetEncoding);
  }

  private boolean binaryKeyEquals(ByteBuffer binaryProbeKey, int probeHash, long targetEncoding, int targetHash) {
    if (storageEngine instanceof BinaryStorageEngine) {
      return probeHash == targetHash && ((BinaryStorageEngine) storageEngine).equalsBinaryKey(binaryProbeKey, targetEncoding);
    } else {
      throw new UnsupportedOperationException("Cannot check binary quality unless configured with a BinaryStorageEngine");
    }
  }
  
  private void expand(long start, int length) {
    if (!tryExpand()) {
      tableExpansionFailure(start, length);
    }
  }

  private boolean tryExpand() {
    if (((float) size) / getTableCapacity() > TABLE_RESIZE_THRESHOLD) {
      return tryExpandTable();
    } else {
      return tryIncreaseReprobe();
    }
  }

  private boolean tryExpandTable() {
    if (tableResizing.get()) {
      throw new AssertionError("Expand requested in context of an existing resize - this should be impossible");
    } else {
      tableResizing.set(Boolean.TRUE);
      try {
        IntData newTable = expandTable(1);
        if (newTable == null) {
          return false;
        } else {
          freeTable(hashtable, reprobeLimit());
          hashtable = newTable;
          removedSlots = 0;
          return true;
        }
      } finally {
        tableResizing.remove();
      }
    }
  }

  private IntData expandTable(int scale) {
    if (hashtable == DESTROYED_TABLE) {
      throw new IllegalStateException("This map/cache has been destroyed");
    }
    
    /* Increase the size of the table to accommodate more entries */
    long newsize = hashtable.size() << scale;

    /* Check we're not hitting max capacity */
    if (newsize <= 0) {
      return null;
    }

    long startTime = -1;

    if (LOGGER.isDebugEnabled()) {
      startTime = System.nanoTime();
      long slots = hashtable.size() / ENTRY_SIZE;
      long newslots = newsize / ENTRY_SIZE;
      LOGGER.debug("Expanding table from {} slots to {} slots [load-factor={}]",
              new Object[] {DebuggingUtils.toBase2SuffixedString(slots),
                            DebuggingUtils.toBase2SuffixedString(newslots),
                            ((float) size) / slots});
    }

    IntData newTable = allocateTable(newsize / ENTRY_SIZE);
    if (newTable == null) {
      return null;
    }

    for (long position = 0; position < hashtable.size(); position += ENTRY_SIZE) {
      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isPresent(entry) && !writeEntry(newTable, entry)) {
        if (LOGGER.isDebugEnabled()) {
          LOGGER.debug("Table expansion from {} slots to {} slots abandoned - not enough table space",
                  DebuggingUtils.toBase2SuffixedString(hashtable.size() / ENTRY_SIZE),
                  DebuggingUtils.toBase2SuffixedString(newsize / ENTRY_SIZE));
        }
        freeTable(newTable);
        return expandTable(scale + 1);
      }
    }

    if (LOGGER.isDebugEnabled()) {
      long time = System.nanoTime() - startTime;
      LOGGER.debug("Table expansion from {} slots to {} slots complete : took {}ms", new Object[] {
              DebuggingUtils.toBase2SuffixedString(hashtable.size() / ENTRY_SIZE),
              DebuggingUtils.toBase2SuffixedString(newsize / ENTRY_SIZE),
              ((float) time) / 1000000});
    }

    return newTable;
  }

  protected boolean tryIncreaseReprobe() {
    if (reprobeLimit() >= getTableCapacity()) {
      return false;
    } else {
      int newReprobeLimit = reprobeLimit() << 1;

      if (newReprobeLimit >= REPROBE_WARNING_THRESHOLD) {
        long slots = getTableCapacity();
        LOGGER.warn("Expanding reprobe sequence from {} slots to {} slots [load-factor={}]",
                new Object[] {reprobeLimit(), newReprobeLimit, ((float) size) / slots});
      } else if (LOGGER.isDebugEnabled()) {
        long slots = getTableCapacity();
        LOGGER.debug("Expanding reprobe sequence from {} slots to {} slots [load-factor={}]",
                new Object[] {reprobeLimit(), newReprobeLimit, ((float) size) / slots});
      }

      reprobeLimit = newReprobeLimit;
      return true;
    }
  }

  private void shrink() {
    if (((float) size) / getTableCapacity() <= currentTableShrinkThreshold) {
      shrinkTable();
    }
  }

  private void shrinkTable() {
    if (tableResizing.get()) {
      LOGGER.debug("Shrink request ignored in the context of an in-process expand - likely self stealing");
    } else {
      tableResizing.set(Boolean.TRUE);
      try {
        float shrinkRatio = (TABLE_RESIZE_THRESHOLD * getTableCapacity()) / size;
        int shrinkShift = Integer.numberOfTrailingZeros(Integer.highestOneBit(Math.max(2, (int) shrinkRatio)));
        IntData newTable = shrinkTable(shrinkShift);
        if (newTable == null) {
          currentTableShrinkThreshold = currentTableShrinkThreshold / 2;
        } else {
          currentTableShrinkThreshold = TABLE_SHRINK_THRESHOLD;
          freeTable(hashtable, reprobeLimit());
          hashtable = newTable;
          removedSlots = 0;
        }
      } finally {
        tableResizing.remove();
      }
    }
  }

  private IntData shrinkTable(int scale) {
    /* Increase the size of the table to accommodate more entries */
    long newsize = hashtable.size() >>> scale;

    /* Check we're not hitting zero capacity */
    if (newsize < ENTRY_SIZE) {
      if (scale > 1) {
        return shrinkTable(scale - 1);
      } else {
        return null;
      }
    }

    long startTime = -1;

    if (LOGGER.isDebugEnabled()) {
      startTime = System.nanoTime();
      long slots = hashtable.size() / ENTRY_SIZE;
      long newslots = newsize / ENTRY_SIZE;
      LOGGER.debug("Shrinking table from {} slots to {} slots [load-factor={}]",
              new Object[] {DebuggingUtils.toBase2SuffixedString(slots),
              DebuggingUtils.toBase2SuffixedString(newslots),
              ((float) size) / slots});
    }

    IntData newTable = allocateTable(newsize / ENTRY_SIZE);
    if (newTable == null) {
      return null;
    }

    for (long position = 0; position < hashtable.size(); position += ENTRY_SIZE) {
      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isPresent(entry) && !writeEntry(newTable, entry)) {
        if (LOGGER.isDebugEnabled()) {
          LOGGER.debug("Table shrinking from {} slots to {} slots abandoned - too little table space",
                  DebuggingUtils.toBase2SuffixedString(hashtable.size() / ENTRY_SIZE),
                  DebuggingUtils.toBase2SuffixedString(newsize / ENTRY_SIZE));
        }
        freeTable(newTable);
        if (scale > 1) {
          return shrinkTable(scale - 1);
        } else {
          return null;
        }
      }
    }

    if (LOGGER.isDebugEnabled()) {
      long time = System.nanoTime() - startTime;
      LOGGER.debug("Table shrinking from {} slots to {} slots complete : took {}ms", new Object[] {
              DebuggingUtils.toBase2SuffixedString(hashtable.size() / ENTRY_SIZE),
              DebuggingUtils.toBase2SuffixedString(newsize / ENTRY_SIZE),
              ((float) time) / 1000000});
    }

    return newTable;
  }

  private boolean writeEntry(IntData table, IntData entry) {
    long start = indexFor(spread(entry.get(KEY_HASHCODE)), table);
    long tableMask = table.size() - 1;

    for (int i = 0; i < reprobeLimit() * ENTRY_SIZE; i += ENTRY_SIZE) {
      long address = (start + i) & tableMask;
      int existingStatus = table.get(address + STATUS);
      if (isTerminating(existingStatus)) {
        table.put(address, entry);
        return true;
      } else if (isRemoved(existingStatus)) {
        throw new AssertionError();
      }
    }

    return false;
  }

  protected static int spread(int hash) {
    int h = hash;
    h += (h << 15) ^ 0xffffcd7d;
    h ^= (h >>> 10);
    h += (h << 3);
    h ^= (h >>> 6);
    h += (h << 2) + (h << 14);
    return h ^ (h >>> 16);
  }

  private IntData allocateTable(long size) {
    IntData newTable = tableSource.allocate(size * ENTRY_SIZE, tableAllocationsSteal, false, null);
    if (newTable != null) {
      int[] zeros = new int[1024 >> 2];
      for (long position = 0; position < newTable.size(); position += zeros.length) {
        long remaining = newTable.size() - position;
        if (remaining < zeros.length) {
          newTable.put(position, zeros, 0, (int) remaining);
        } else {
          newTable.put(position, zeros);
        }
      }
    }
    return newTable;
  }

  private void freeTable(IntData table, int finalReprobe) {
    if (hasUsedIterators) {
      pendingTableFrees.put(table, new PendingPage(table, finalReprobe));
    } else {
      freeTable(table);
    }
  }

  private void freeTable(IntData table) {
    tableSource.free(table);
  }

  private int reprobeLimit() {
    return reprobeLimit;
  }

  class EntrySet extends AbstractSet<Entry<K, V>> {

    @Override
    public Iterator<Map.Entry<K, V>> iterator() {
      return new EntryIterator();
    }

    @Override
    public boolean contains(Object o) {
      if (!(o instanceof Entry<?, ?>)) {
        return false;
      }
      Entry<?, ?> e = (Entry<?, ?>) o;
      V value = get(e.getKey());
      return value != null && value.equals(e.getValue());
    }

    @Override
    public boolean remove(Object o) {
      return removeMapping(o);
    }

    @Override
    public int size() {
      return size;
    }

    @Override
    public void clear() {
      OffHeapHashMap.this.clear();
    }
  }

  class EncodingSet extends AbstractSet<Long> {
    @Override
    public Iterator<Long> iterator() {
      return new EncodingIterator();
    }

    @Override
    public int size() {
      return size;
    }

    @Override
    public boolean contains(Object o) {
      // We could allow the impl from AbstractSet to run but that won't perform as well as you'd expect Set.contains() to run
      throw new UnsupportedOperationException();
    }
  }

  class KeySet extends AbstractSet<K> {

    @Override
    public Iterator<K> iterator() {
      return new KeyIterator();
    }

    @Override
    public boolean contains(Object o) {
      return OffHeapHashMap.this.containsKey(o);
    }

    @Override
    public boolean remove(Object o) {
      return OffHeapHashMap.this.remove(o) != null;
    }

    @Override
    public int size() {
      return OffHeapHashMap.this.size();
    }

    @Override
    public void clear() {
      OffHeapHashMap.this.clear();
    }
  }

  abstract class HashIterator<T> implements Iterator<T> {

    final int expectedModCount; // For fast-fail
    /*
     * We *must* keep a reference to the original table object that is the key
     * in the weak map to prevent the table from being freed
     */
    final IntData table;
    
    int position = 0;
    T next = null; // next entry to return

    HashIterator() {
      hasUsedIterators = true;
      table = hashtable;
      expectedModCount = modCount;

      if (size > 0) { // advance to first entry
        while (position < table.size()) {
          IntData entry = table.slice(position, ENTRY_SIZE);
          position += ENTRY_SIZE;
          
          if (isPresent(entry)) {
            next = create(entry);
            break;
          }
        }
      }
    }

    protected abstract T create(IntData entry);

    @Override
    public boolean hasNext() {
      return next != null;
    }

    @Override
    public T next() {
      checkForConcurrentModification();

      T e = next;
      if (e == null) {
        throw new NoSuchElementException();
      }

      next = null;
      while (position < table.size()) {
        IntData entry = table.slice(position, ENTRY_SIZE);
        position += ENTRY_SIZE;

        if (isPresent(entry)) {
          next = create(entry);
          break;
        }
      }
      return e;
    }

    @Override
    public void remove() {
      throw new UnsupportedOperationException();
    }

    protected void checkForConcurrentModification() {
      if (modCount != expectedModCount) {
        throw new ConcurrentModificationException();
      }
    }
  }

  static class PendingPage {
    final IntData table;
    final int reprobe;

    PendingPage(IntData table, int reprobe) {
      this.table = table;
      this.reprobe = reprobe;
    }
  }

  private void freePendingTables() {
    if (hasUsedIterators) {
      pendingTableFrees.reap();
    }
  }

  private void cleanPendingTables(int hash, long encoding) {
    if (hasUsedIterators) {
      pendingTableFrees.reap();
      
      Iterator<PendingPage> it = pendingTableFrees.values();
      while (it.hasNext()) {
        PendingPage pending = it.next();
        
        IntData pendingTable = pending.table;
        long position = indexFor(spread(hash), pendingTable);
        
        for (int i = 0; i < pending.reprobe; i++) {
          if (position == pendingTable.size()) {
            position = 0;
          }
  
          IntData entry = pendingTable.slice(position, ENTRY_SIZE);
  
          if (isTerminating(entry)) {
            break;
          } else if (isPresent(entry) && (hash == entry.get(KEY_HASHCODE)) && (encoding == readLong(entry, ENCODING))) {
            entry.put(STATUS, STATUS_REMOVED);
            break;
          } else {
            position += ENTRY_SIZE;
          }
        }
      }
    }
  }

  private void wipePendingTables() {
    if (hasUsedIterators) {
      pendingTableFrees.reap();
      
      int[] zeros = new int[1024 >> 2];
      
      Iterator<PendingPage> it = pendingTableFrees.values();
      while (it.hasNext()) {
        PendingPage pending = it.next();
        
        IntData pendingTable = pending.table;

        for (long position = 0; position < pendingTable.size(); position += zeros.length) {
          long remaining = pendingTable.size() - position;
          if (remaining < zeros.length) {
            pendingTable.put(position, zeros, 0, (int) remaining);
          } else {
            pendingTable.put(position, zeros);
          }
        }
      }
    }
  }
  
  class KeyIterator extends HashIterator<K> {
    KeyIterator() {
      super();
    }

    @Override
    @SuppressWarnings("unchecked")
    protected K create(IntData entry) {
      return (K) storageEngine.readKey(readLong(entry, ENCODING), entry.get(KEY_HASHCODE));
    }

  }

  class EntryIterator extends HashIterator<Entry<K, V>> {
    EntryIterator() {
      super();
    }

    @Override
    protected Entry<K, V> create(IntData entry) {
      return new DirectEntry(entry);
    }
  }

  class EncodingIterator extends HashIterator<Long> {
    EncodingIterator() {
      super();
    }

    @Override
    protected Long create(IntData entry) {
      return readLong(entry, ENCODING);
    }
  }

  class DirectEntry implements Entry<K, V> {

    private final K key;
    private final V value;

    @SuppressWarnings("unchecked")
    DirectEntry(IntData entry) {
      this.key = (K) storageEngine.readKey(readLong(entry, ENCODING), entry.get(KEY_HASHCODE));
      this.value = (V) storageEngine.readValue(readLong(entry, ENCODING));
    }

    @Override
    public K getKey() {
      return key;
    }

    @Override
    public V getValue() {
      return value;
    }

    @Override
    public V setValue(V value) {
      throw new UnsupportedOperationException();
    }

    @Override
    public int hashCode() {
      return key.hashCode() ^ value.hashCode();
    }

    @Override
    public boolean equals(Object o) {
      if (o instanceof Entry<?, ?>) {
        Entry<?, ?> e = (Entry<?, ?>) o;
        return key.equals(e.getKey()) && value.equals(e.getValue());
      } else {
        return false;
      }
    }

    @Override
    public String toString() {
      return key + "=" + value;
    }
  }

  /*
   * remove used by EntrySet
   */
  @SuppressWarnings("unchecked")
  protected boolean removeMapping(Object o) {
    freePendingTables();

    if (!(o instanceof Entry<?, ?>)) {
      return false;
    }

    Entry<K, V> e = (Entry<K, V>) o;

    Object key = e.getKey();
    int hash = key.hashCode();

    long position = indexFor(spread(hash));

    for (int i = 0; i < reprobeLimit(); i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return false;
      } else if (isPresent(entry) && keyEquals(key, hash, readLong(entry, ENCODING), entry.get(KEY_HASHCODE))
          && storageEngine.equalsValue(e.getValue(), readLong(entry, ENCODING))) {
        storageEngine.freeMapping(readLong(entry, ENCODING), entry.get(KEY_HASHCODE), true);

        entry.put(STATUS, STATUS_REMOVED);
        slotRemoved(entry);
        shrink();
        return true;
      } else {
        position += ENTRY_SIZE;
      }
    }

    return false;
  }

  @Override
  public boolean evict(long index, boolean shrink) {
    return false;
  }

  protected void removeAtTableOffset(long offset, boolean shrink) {
    IntData entry = hashtable.slice(offset, ENTRY_SIZE);

    if (isPresent(entry)) {
      storageEngine.freeMapping(readLong(entry, ENCODING), entry.get(KEY_HASHCODE), true);

      entry.put(STATUS, STATUS_REMOVED);
      slotRemoved(entry);
      if (shrink) {
        shrink();
      }
    } else {
      throw new AssertionError();
    }
  }

  @SuppressWarnings("unchecked")
  protected V getAtTableOffset(long offset) {
    IntData entry = hashtable.slice(offset, ENTRY_SIZE);

    if (isPresent(entry)) {
      return (V) storageEngine.readValue(readLong(entry, ENCODING));
    } else {
      throw new AssertionError();
    }
  }

  protected Entry<K, V> getEntryAtTableOffset(long offset) {
    IntData entry = hashtable.slice(offset, ENTRY_SIZE);

    if (isPresent(entry)) {
      return new DirectEntry(entry);
    } else {
      throw new AssertionError();
    }
  }

  @Override
  public Long getSlotForHashAndEncoding(int hash, long encoding, long mask) {
    long position = indexFor(spread(hash));
    
    int limit = reprobeLimit();

    for (int i = 0; i < limit; i++) {
      if (position == hashtable.size()) {
        position = 0;
      }

      IntData entry = hashtable.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return null;
      } else if (isPresent(entry) && (hash == entry.get(KEY_HASHCODE)) && ((encoding & mask) == (readLong(entry, ENCODING) & mask))) {
        return position;
      } else {
        position += ENTRY_SIZE;
      }
    }

    return null;
  }

  @Override
  public boolean updateEncoding(int hash, long oldEncoding, long newEncoding, long mask) {
    boolean updated = updateEncodingInTable(hashtable, reprobeLimit(), hash, oldEncoding, newEncoding, mask);

    if (hasUsedIterators) {
      pendingTableFrees.reap();
      
      Iterator<PendingPage> it = pendingTableFrees.values();
      while (it.hasNext()) {
        PendingPage pending = it.next();
        updated |= updateEncodingInTable(pending.table, pending.reprobe, hash, oldEncoding, newEncoding, mask);
      }
    }
    return updated;
  }

  private static boolean updateEncodingInTable(IntData table, int limit, int hash, long oldEncoding, long newEncoding, long mask) {
    long position = indexFor(spread(hash), table);

    for (int i = 0; i < limit; i++) {
      if (position == table.size()) {
        position = 0;
      }

      IntData entry = table.slice(position, ENTRY_SIZE);

      if (isTerminating(entry)) {
        return false;
      } else if (isPresent(entry) && (hash == entry.get(KEY_HASHCODE)) && ((oldEncoding & mask) == (readLong(entry, ENCODING) & mask))) {
        entry.put(position, createEntry(hash, (readLong(entry, ENCODING) & ~mask) | newEncoding & mask, entry.get(STATUS)));
        return true;
      } else {
        position += ENTRY_SIZE;
      }
    }
    return false;
  }

  @FindbugsSuppressWarnings("VO_VOLATILE_INCREMENT")
  private void slotRemoved(IntData entry) {
    modCount++;
    removedSlots++;
    size--;
    cleanPendingTables(entry.get(KEY_HASHCODE), readLong(entry, ENCODING));
    removed(entry);
  }

  @FindbugsSuppressWarnings("VO_VOLATILE_INCREMENT")
  private void slotAdded(IntData entry) {
    modCount++;
    size++;
    added(entry);
  }

  @FindbugsSuppressWarnings("VO_VOLATILE_INCREMENT")
  private void slotUpdated(IntData entry, long oldEncoding) {
    modCount++;
    cleanPendingTables(entry.get(KEY_HASHCODE), oldEncoding);
    updated(entry);
  }

  protected void added(IntData entry) {
    //no-op
  }

  protected void hit(IntData entry) {
    //no-op
  }

  protected void removed(IntData entry) {
    //no-op
  }

  protected void updated(IntData entry) {
    //no-op
  }
  
  protected void tableExpansionFailure(long start, int length) {
    StringBuilder sb = new StringBuilder("Failed to expand table.\n");
    sb.append("Current Table Size (slots) : ").append(getTableCapacity()).append('\n');
    sb.append("Resize Will Require        : ").append(DebuggingUtils.toBase2SuffixedString(getTableCapacity() * ENTRY_SIZE * (Integer.SIZE / Byte.SIZE) * 2)).append("B\n");
    sb.append("Table Buffer Source        : ").append(tableSource);
    throw new OversizeMappingException(sb.toString());
  }

  protected void storageEngineFailure(Object failure) {
    StringBuilder sb = new StringBuilder("Storage engine failed to store: ");
    sb.append(failure).append('\n');
    sb.append("StorageEngine: ").append(storageEngine);
    throw new OversizeMappingException(sb.toString());
  }

  /* MapStatistics Methods */
  @Override
  public long getSize() {
    return size;
  }

  @Override
  public long getTableCapacity() {
    IntData table = hashtable;
    return table == null ? 0 : table.size() / ENTRY_SIZE;
  }

  @Override
  public long getUsedSlotCount() {
    return getSize();
  }

  @Override
  public long getRemovedSlotCount() {
    return removedSlots;
  }

  @Override
  public int getReprobeLength() {
    return reprobeLimit();
  }

  @Override
  public long getAllocatedMemory() {
    return getDataAllocatedMemory() + (getTableCapacity() * ENTRY_SIZE * (Integer.SIZE / Byte.SIZE));
  }

  @Override
  public long getOccupiedMemory() {
    return getDataOccupiedMemory() + (getUsedSlotCount() * ENTRY_SIZE * (Integer.SIZE / Byte.SIZE));
  }
  
  @Override
  public long getVitalMemory() {
    return getDataVitalMemory() + (getTableCapacity() * ENTRY_SIZE * (Integer.SIZE / Byte.SIZE));
  }

  @Override
  public long getDataAllocatedMemory() {
    return storageEngine.getAllocatedMemory();
  }

  @Override
  public long getDataOccupiedMemory() {
    return storageEngine.getOccupiedMemory();
  }

  @Override
  public long getDataVitalMemory() {
    return storageEngine.getVitalMemory();
  }

  @Override
  public long getDataSize() {
    return storageEngine.getDataSize();
  }

  @Override
  public boolean isThiefForTableAllocations() {
    return tableAllocationsSteal;
  }

  @Override
  public Lock readLock() {
    return NoOpLock.INSTANCE;
  }

  @Override
  public Lock writeLock() {
    return NoOpLock.INSTANCE;
  }

  public StorageEngine<? super K, ? super V> getStorageEngine() {
    return storageEngine;
  }

}
